{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8db694b2-b861-4814-8094-c92509dee919",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Reflecting on Unmasking AI: Changing the Conversation\"\n",
    "description: \"This blog post will reflect on a point made about AI discourse in the book Unmasking AI: My Mission to Protect What Is Human in a World of Machines.\" \n",
    "author: \"Layla\"\n",
    "date: \"10/25/2025\"\n",
    "categories:\n",
    "  - Living With A Book\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac2818e-c5ec-46ea-b469-8f155a222eca",
   "metadata": {},
   "source": [
    "Dr. Buolamwini points out how many examples of AI risks feel inconsequential or \"cute,\" for example, an AI agent that uses its intelligence to coerce individuals into diverting resources toward paper clip production, or a computer vision system that mistakes blueberry cupcakes for chihuahuas.\n",
    "\n",
    "“[But these are the kinds of] ideas and examples being presented in elite institutions, used in college curricula, and shared in a manner that shapes the discourse about the future of AI,” she writes. Ultimately, much of the current conversation in academia and business contexts about AI risks is speculative and distant. Describing them in such ways, though, minimizes existing AI harms at best, and, at worst, drowns out the discussion of them.\n",
    "\n",
    "Throughout Dr. Buolamwini’s research, she worked with facial recognition software that struggled to identify and classify darker-skinned individuals. Computer vision algorithms like the ones she worked with were being used to develop tech products, and in an application like a self-driving car, for example, the bias in those algorithsms could have serious consequences that disproportionately affect Black people. \n",
    "\n",
    "While there is much more to be said on this topic, it is clear that how we talk about AI risk/harm matters just as much as having the discussion at all. The examples we use determine how people characterize AI and assess its risks, and when those examples are hyperbolic or overly hypothetical, we do a disservice to the real AI harms that we face today. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
